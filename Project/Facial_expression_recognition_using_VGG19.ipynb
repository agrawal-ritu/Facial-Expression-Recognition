{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIxe1pZ5ySzt"
   },
   "source": [
    "# Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toU-JucSzcNr"
   },
   "source": [
    "## Abstract\n",
    "In this notebook, we used VGG19 Neural Network for testing for the best testing accuracy to see how good will our model predict the expressions on human faces and categorize them into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "\n",
    "##### Facial Expression Recognition\n",
    "\n",
    "The dataset we have chosen is Facial Expression Recognition fer2013. The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "\n",
    "The \"emotion\" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The \"pixels\" column contains a string surrounded in quotes for each image. The contents of this string a space-separated pixel values in row major order. Our task is to predict the \"emotion\" column.\n",
    "\n",
    "The training set consists of 28,709 examples. The public test set consists of 3,589 examples. The final test set, consists of another 3,589 examples.\n",
    "\n",
    "This dataset was prepared by Pierre-Luc Carrier and Aaron Courville, as part of an ongoing research project. They have graciously provided the workshop organizers with a preliminary version of their dataset to use for this contest.\n",
    "\n",
    "Link to the dataset - https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "\n",
    "`Conclusion` - We train VGG19 models on certain parameters, resulting in the value of accuracy (which is how our goodness of model is evaluated)  as follows,  VGG19 - `57.0%`. And thus helping us in deciding the best model for expression prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-n26KAF6sJ5"
   },
   "source": [
    "#### VGG19\n",
    "It has 19 layers with multiple 3X3 kernel-sized filters one after another. With a given receptive field(the effective area size of input image on which output depends), multiple stacked smaller size kernel is better than the one with a larger size kernel because multiple non-linear layers increases the depth of the network which enables it to learn more complex features, and that too at a lower cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4062,
     "status": "ok",
     "timestamp": 1556239258470,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "bQOUz78xQZtx",
    "outputId": "e29be367-1799-48fa-e54d-d2268a49cfac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\ritua\\Anaconda37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy5AUbimQZt2"
   },
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "with open(\"fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMqt63DTQZt4"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#creating training and testing data \n",
    "for i in range(1,num_of_instances):\n",
    "    emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "    val = img.split(\" \")\n",
    "            \n",
    "    pixels = np.array(val, 'float32')\n",
    "        \n",
    "    emotion = keras.utils.to_categorical(emotion, 7)\n",
    "    \n",
    "    if 'Training' in usage:\n",
    "        y_train.append(emotion)\n",
    "        x_train.append(pixels)\n",
    "    elif 'PublicTest' in usage:\n",
    "        y_test.append(emotion)\n",
    "        x_test.append(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkmcykzcQZt5"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train, 'float32')\n",
    "y_train = np.asarray(y_train, 'float32')\n",
    "x_test = np.asarray(x_test, 'float32')\n",
    "y_test = np.asarray(y_test, 'float32')\n",
    "\n",
    "x_train = x_train.reshape([-1, 48, 48, 1])\n",
    "x_test = x_test.reshape([-1, 48, 48, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422,
     "status": "ok",
     "timestamp": 1556239289845,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "PWeIOLVbQZt9",
    "outputId": "e54c7ac5-2466-4a31-cae1-c71003f1b4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "\n",
    "# Building 'VGG Network'\n",
    "network = input_data(shape=[None, 48, 48, 1])\n",
    "\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = fully_connected(network, 1024, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 1024, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 7, activation='softmax')\n",
    "\n",
    "network = regression(network, optimizer='rmsprop',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5214,
     "status": "ok",
     "timestamp": 1556239308962,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "UlxEKq_JQZuA",
    "outputId": "93d9007d-0ca3-4ad4-f1d0-58358752aa3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Using DNN(Deep Neural Network) from tflearn\n",
    "model = tflearn.DNN(network, checkpoint_path='model_vgg',\n",
    "                    max_checkpoints=1, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bdFWF-shmC-4",
    "outputId": "e454946c-2cfc-4cf3-8d86-c0e87b6e231d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /content/vgg19_final.tfl\n"
     ]
    }
   ],
   "source": [
    "#loading the previously trained model to retrain it\n",
    "model.load('vgg19_final.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2039,
     "status": "ok",
     "timestamp": 1556246375933,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "HiQ8CUtfllmf",
    "outputId": "5d5f4cba-0735-4a0b-d9b8-cdc8d53fb607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 44999  | total loss: \u001b[1m\u001b[32m0.08969\u001b[0m\u001b[0m | time: 24.204s\n",
      "| RMSProp | epoch: 200 | loss: 0.08969 - acc: 0.9871 -- iter: 28672/28709\n",
      "Training Step: 45000  | total loss: \u001b[1m\u001b[32m0.08650\u001b[0m\u001b[0m | time: 24.313s\n",
      "| RMSProp | epoch: 200 | loss: 0.08650 - acc: 0.9868 -- iter: 28709/28709\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(x_train, y_train, n_epoch=200, shuffle=True,\n",
    "          show_metric=True, batch_size=128, snapshot_step=20,\n",
    "          snapshot_epoch=False, run_id='vgg_emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2805,
     "status": "ok",
     "timestamp": 1556246682861,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "LxuWsFmPQZuC",
    "outputId": "3007867c-5c40-4bd2-9ceb-ea778d5d5305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy:  [0.5700752298731963]\n"
     ]
    }
   ],
   "source": [
    "#evaluating the testing score\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test accuarcy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZTmzN7JfbjG"
   },
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "model.save('vgg19_emotion.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lvy6V7iyQZuE"
   },
   "outputs": [],
   "source": [
    "#Function to plot graph of the expressions of the custom images\n",
    "def detect_emotion(emotions):\n",
    "   objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "   y_pos = np.arange(len(objects))\n",
    "\n",
    "   plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "   plt.xticks(y_pos, objects)\n",
    "   plt.ylabel('percentage')\n",
    "   plt.title('emotion')\n",
    "\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCAxudiGQZuG"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1556247055146,
     "user": {
      "displayName": "Ritu Agrawal",
      "photoUrl": "https://lh4.googleusercontent.com/-oft-AbUL8VY/AAAAAAAAAAI/AAAAAAAAJ-I/lI9p_eBy_34/s64/photo.jpg",
      "userId": "17570593336691745027"
     },
     "user_tz": 240
    },
    "id": "muiYg2g5QZuI",
    "outputId": "e46e28bc-bc42-4947-a6a0-d9f3fdb04272"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF2RJREFUeJzt3Xm4JXV95/H3h8UBBRu1Oxo2G7TR\nIGNUWhCXCS4o8ig4ESMIUQwjjzMBt5hHjIgMLqMxT+LjiEsTGQKoCDJIx7QSIRBQg9KA7APpNCCN\nRhqUTSTQ8J0/qm5xuNzl9O1b99D0+/U897lVv/M7Vd9Tt879nFpPqgpJkgA2GnUBkqTHDkNBktQx\nFCRJHUNBktQxFCRJHUNBktQxFKQ5kOS7Sd4x6jqk6cTrFKTZleQY4NlVdfCoa5HWllsKkqSOoaAN\nSpKtk5yRZHWSG5K8p20/JsnpSU5JcneSK5PslOTDSW5NcnOS146bztIkv0qyIsm72va9gb8A3prk\nniSXt+3nJ/lv7fBGSY5KclM77ZOSzGsfW5ikkrwjyc+S3JbkI3O9nLThMhS0wUiyEfD3wOXANsCr\ngfcleV3b5Y3AycBTgMuAs2neI9sAxwJfGZjcqcAqYGtgf+BTSV5VVd8DPgV8s6q2qKrfn6CUQ9qf\nVwI7AlsAXxjX5+XAc9oaj07yezN+4dJaMBS0IXkxsKCqjq2q+6tqJXA8cED7+IVVdXZVrQFOBxYA\nn66qB2hCYGGSrZJsB7wM+FBV3VdVPwX+Fnj7kHUcBPx1Va2sqnuADwMHJNlkoM//rKrfVtXlNCE2\nUbhIs26T6btIjxvPBLZOcsdA28bAhcBNwC8H2n8L3FZVDw6MQ/OpfmvgV1V190D/m4DFQ9axddt/\n8LmbAE8faPv3geF72/lKvXNLQRuSm4EbqmqrgZ8tq2qftZzOz4GnJtlyoG174JZ2eLpT+n5OE1CD\nz13DI0NJGglDQRuSnwB3J/lQks2TbJxklyQvXpuJVNXNwI+A/5VksyTPBw4FTmm7/JJmV9Nk769v\nAO9PskOSLXj4GMSaGb0qaRYZCtpgtLuC3gC8ALgBuI3mWMC8GUzuQGAhzaf+M4GPVdU57WOnt79v\nT3LpBM89geaA9gVtHfcBR8ygBmnWefGaJKnjloIkqWMoSJI6hoIkqWMoSJI6693Fa/Pnz6+FCxeO\nugxJWq9ccsklt1XVgun6rXehsHDhQpYvXz7qMiRpvZLkpul7uftIkjTAUJAkdQwFSVLHUJAkdQwF\nSVLHUJAkdXoLhSQntN8/e9UkjyfJ59vvt70iyYv6qkWSNJw+txROBPae4vHXA4van8OAL/VYiyRp\nCL2FQlVdAPxqii77ASdV4yJgqyS/21c9kqTpjfKK5m1ovh5xzKq27RfjOyY5jGZrgu23335OipOk\nv/n+9aMu4RHev9dOvc9jvTjQXFVLqmpxVS1esGDaW3dIkmZolKFwC7DdwPi2PPzF55KkERhlKCwF\n3t6ehfQS4M6qetSuI0nS3OntmEKSbwB7AvOTrAI+BmwKUFVfBpYB+wArgHuBd/ZViyRpOL2FQlUd\nOM3jBfxpX/OXJK299eJAsyRpbhgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgK\nkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSO\noSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqROr6GQZO8k1yVZkeTI\nCR7fPsl5SS5LckWSffqsR5I0td5CIcnGwHHA64GdgQOT7Dyu21HAaVX1QuAA4It91SNJml6fWwq7\nASuqamVV3Q+cCuw3rk8BT26H5wE/77EeSdI0+gyFbYCbB8ZXtW2DjgEOTrIKWAYcMdGEkhyWZHmS\n5atXr+6jVkkSoz/QfCBwYlVtC+wDnJzkUTVV1ZKqWlxVixcsWDDnRUrShqLPULgF2G5gfNu2bdCh\nwGkAVfUvwGbA/B5rkiRNoc9QuBhYlGSHJE+gOZC8dFyfnwGvBkjyezSh4P4hSRqR3kKhqtYAhwNn\nA9fSnGV0dZJjk+zbdvsz4F1JLge+ARxSVdVXTZKkqW3S58SrahnNAeTBtqMHhq8BXtZnDZKk4Y36\nQLMk6THEUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwF\nSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVJn\n6FBI8vIk72yHFyTZob+yJEmjMFQoJPkY8CHgw23TpsApfRUlSRqNYbcU/iuwL/AbgKr6ObBlX0VJ\nkkZj2FC4v6oKKIAkT+qvJEnSqAwbCqcl+QqwVZJ3AecAx/dXliRpFDYZplNV/VWSvYC7gOcAR1fV\n93utTJI054YKBYA2BAwCSXocG/bso7uT3DXu5+YkZybZcYrn7Z3kuiQrkhw5SZ8/SnJNkquTfH2m\nL0SStO6G3VL4HLAK+DoQ4ADgWcClwAnAnuOfkGRj4Dhgr/a5FydZWlXXDPRZRHOa68uq6tdJfmfm\nL0WStK6GPdC8b1V9parurqq7qmoJ8Lqq+ibwlEmesxuwoqpWVtX9wKnAfuP6vAs4rqp+DVBVt87g\nNUiSZsmwoXBvu5tno/bnj4D72sdqkudsA9w8ML6qbRu0E7BTkh8muSjJ3kNXLkmadcOGwkHAHwO3\nAr9shw9Osjlw+DrMfxNgEc3upwOB45NsNb5TksOSLE+yfPXq1eswO0nSVIY9JXUl8MZJHv7BJO23\nANsNjG/btg1aBfy4qh4AbkhyPU1IXDxu/kuAJQCLFy+ebMtEkrSOhgqFJJsBhwLPAzYba6+qP5ni\naRcDi9ob591Cc3D6beP6fJtmC+H/JJlPsztp5dDVS5Jm1bC7j04GngG8Dvhnmk/9d0/1hKpaQ7Nr\n6WzgWuC0qro6ybFJ9m27nQ3cnuQa4Dzgz6vq9rV/GZKk2TDsKanPrqq3JNmvqv6uvZ7gwumeVFXL\ngGXj2o4eGC7gA+2PJGnEht1SeKD9fUeSXYB5gNcUSNLjzLBbCkuSPAU4ClgKbAF8tLeqJEkjMWwo\nnNteYHYBsCOA37wmSY8/w+4+OmOCtm/NZiGSpNGbckshyXNpTkOdl+QPBx56MgOnpkqSHh+m2330\nHOANwFY88uK1u2nuWyRJehyZMhSq6izgrCR7VNW/zFFNkqQRGfZA84okfwEsHHzONFc0S5LWM8OG\nwlk0F6udAzzYXzmSpFEaNhSeWFUf6rUSSdLIDXtK6neS7NNrJZKkkRs2FN5LEwz3td/PfHeSu/os\nTJI094b9PoUt+y5EkjR6Q20ppHFwko+249sl2a3f0iRJc23Y3UdfBPbg4S/JuQc4rpeKJEkjM+zZ\nR7tX1YuSXAZQVb9O8oQe65IkjcDQ36eQZGOgAJIsAB7qrSpJ0kgMGwqfB84EfifJJ4EfAJ/qrSpJ\n0kgMe/bR15JcArwaCPCmqrq218okSXNuqFBI8hLg6qo6rh1/cpLdq+rHvVYnSZpTw+4++hLNGUdj\n7mnbJEmPI8OGQqqqxkaq6iGGP3NJkrSeGDYUViZ5T5JN25/3Aiv7LEySNPeGDYV3Ay8FbgFWAbsD\nh/VVlCRpNKbdBdRen3BQVR0wB/VIkkZo2i2FqnoQOHAOapEkjdiwB4t/mOQLwDeB34w1VtWlvVQl\nSRqJYUPhBe3vYwfaCnjV7JYjSRqlYa9ofmXfhUiSRm/Y71N4epKvJvluO75zkkP7LU2SNNeGPSX1\nROBsYOt2/HrgfX0UJEkanWFDYX5VnUZ7u+yqWgM82FtVkqSRGDYUfpPkaTz8fQovAe7srSpJ0kgM\nGwofAJYCOyb5IXAScMR0T0qyd5LrkqxIcuQU/d6cpJIsHrIeSVIPhj0l9RqaL9m5F7gb+DbNcYVJ\ntVdCHwfsRXNrjIuTLK2qa8b12xJ4L+BtuCVpxIbdUjgJeC7Nt639b2An4ORpnrMbsKKqVlbV/cCp\nwH4T9Ps48BngviFrkST1ZNgthV2qaueB8fOSXDNp78Y2wM0D42M30uskeRGwXVX9Q5I/n2xCSQ6j\nvQHf9ttvP2TJkqS1NeyWwqXtwWUAkuwOLF+XGSfZCPhr4M+m61tVS6pqcVUtXrBgwbrMVpI0hWG3\nFHYFfpTkZ+349sB1Sa4EqqqeP8FzbgG2Gxjftm0bsyWwC3B+EoBnAEuT7FtV6xQ4kqSZGTYU9p7B\ntC8GFiXZgSYMDgDeNvZgVd0JzB8bT3I+8EEDQZJGZ9h7H920thOuqjVJDqe5Enpj4ISqujrJscDy\nqlq6ttOUJPWr1+9ZrqplwLJxbUdP0nfPPmuRJE1v2APNkqQNgKEgSeoYCpKkjqEgSeoYCpKkjqEg\nSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoY\nCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKk\njqEgSer0GgpJ9k5yXZIVSY6c4PEPJLkmyRVJzk3yzD7rkSRNrbdQSLIxcBzwemBn4MAkO4/rdhmw\nuKqeD3wL+Mu+6pEkTa/PLYXdgBVVtbKq7gdOBfYb7FBV51XVve3oRcC2PdYjSZpGn6GwDXDzwPiq\ntm0yhwLfneiBJIclWZ5k+erVq2exREnSoMfEgeYkBwOLgc9O9HhVLamqxVW1eMGCBXNbnCRtQDbp\ncdq3ANsNjG/btj1CktcAHwH+oKr+o8d6JEnT6HNL4WJgUZIdkjwBOABYOtghyQuBrwD7VtWtPdYi\nSRpCb6FQVWuAw4GzgWuB06rq6iTHJtm37fZZYAvg9CQ/TbJ0kslJkuZAn7uPqKplwLJxbUcPDL+m\nz/lLktbOY+JAsyTpscFQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJ\nUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQ\nkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUqfXUEiyd5LrkqxIcuQE\nj/+nJN9sH/9xkoV91iNJmlpvoZBkY+A44PXAzsCBSXYe1+1Q4NdV9Wzgb4DP9FWPJGl6fW4p7Aas\nqKqVVXU/cCqw37g++wF/1w5/C3h1kvRYkyRpCpv0OO1tgJsHxlcBu0/Wp6rWJLkTeBpw22CnJIcB\nh7Wj9yS5rpeKhzefcTWuB6y5f+tbvWDNc2VWav7Auj39mcN06jMUZk1VLQGWjLqOMUmWV9XiUdex\nNqy5f+tbvWDNc2V9qrnP3Ue3ANsNjG/btk3YJ8kmwDzg9h5rkiRNoc9QuBhYlGSHJE8ADgCWjuuz\nFHhHO7w/8E9VVT3WJEmaQm+7j9pjBIcDZwMbAydU1dVJjgWWV9VS4KvAyUlWAL+iCY71wWNmV9Za\nsOb+rW/1gjXPlfWm5vjBXJI0xiuaJUkdQ0GS1DEU1jNJjknywSTHJnnNHMzvTRNciT4b031PkmuT\nfG22p72ukixMctWo6xil9XEZJFmWZKtR1zGZdpm+bYbPvWe265mMoTDL2lNre1dVR1fVOXMwqzfR\n3KZktv0PYK+qOmimE5irZa3RGPbvm8ZGVbVPVd3Rd13rYCEwYSg8ltblDT4Uknw7ySVJrm6vnCbJ\nPUk+meTyJBcleXrb/qx2/MoknxhL7yR7JrkwyVLgmvZT/PsG5vHJJO9dhxo/kuT6JD8AntO2nZhk\n/3b400muSXJFkr8aotbvDEz7C0kOmWg6SV4K7At8NslPkzxrpq9h3Ov5MrAj8N32tZ2Q5CdJLkuy\nX9tnYbtML21/XjpQf7esZ6OeSWyc5Ph2vfjHJJsneVeSi9v14owkT2xrOjHJl5Msb/9Ob2jbD0ly\nVpLzk/xrko+17bO6fkwlyZOS/ENb81VJ3prk6PZ1XJVkSdLcWibJrm2/y4E/7bmGG5PMbx9fnOT8\ndviYJCcn+SHNmYmTLcOFaW62eRJwFbDd2DQnmt/A6/vn9v1+dpLfHbL+hWm2asevD89K8r12ehcm\neW7bv3tvtuNjn/I/DbyifS+9v31tS5P8E3Buki2SnNuu71eOvRfmXFVt0D/AU9vfm9OsXE8DCnhj\n2/6XwFHt8HeAA9vhdwP3tMN7Ar8BdmjHFwKXtsMbAf8GPG2G9e0KXAk8EXgysAL4IHAizbUdTwOu\n4+EzybYaotbvDEz/C8AhU0znRGD/Hpb7jTSX/n8KOHhsnsD1wJPa17tZ276I5jTmRy3rntaJhcAa\n4AXt+GnAwYN/Q+ATwBEDy+h77d96Ec0tXTZrl+sv2mU7tn4tns31Y4jX8mbg+IHxeWPrfDt+8sC6\nfgXwX9rhzwJX9VjDjcD8dnwxcH47fAxwCbB5Oz7VMnwIeMkE69RE89sU+BGwoG17K81p8uuyPpwL\nLGrbdqe5zupR7xkmf+8d0q4rY/+DNgGe3A7Pp3mvZ3Aac/GzwW8pAO9pPxldRHN19SLgfpp/qtCs\noAvb4T2A09vhr4+bzk+q6gaAqroRuD3JC4HXApdV1Uyv1H4FcGZV3VtVd/HoCwDvBO4DvprkD4F7\nh6h1IpNNp2+vBY5M8lPgfJp/ptvTvImPT3IlzesY3IXVLese3VBVP22Hx9aBXdpPhFcCBwHPG+h/\nWlU9VFX/CqwEntu2f7+qbq+q3wL/F3j5LK8f07kS2CvJZ5K8oqruBF6Z5lb1VwKvAp6XZl/8VlV1\nQfu8k3uuYSpL2+U15lHLsG2/qaouGnJ+zwF2Ab7frmtH0dxlYVgTrQ8vBU5vp/cVYKgtj3G+X1W/\naocDfCrJFcA5NPeGe/oMprlOHjP7sUYhyZ7Aa4A9quredhN2M+CBauMZeJDhltNvxo3/Lc0ngWcA\nJ8xGvROp5iLB3YBX02w5HE7zRp/MGh6523CzGU5ntgR4c1U94iaHSY4Bfgn8flvvfQMPj1/WffiP\ngeEHaT6lngi8qaouT7PLbc+BPuMv+Klp2udq/bg+yYuAfYBPJDmXZtfQ4qq6uV3Om/U1/ylqGFwP\nx89//N93smU44XowyfzOBK6uqj1m+DLGrw9PB+6oqhdM0Ld7bUk2Ap4wxXQHX8NBwAJg16p6IMmN\n9Py3mciGvqUwj+b7HO5t9we+ZJr+F9FsmsL0V1+fCewNvJjmqu6ZugB4U7sPc0vgjYMPJtkCmFdV\ny4D30/wTnarWm4Cd03zB0VY0ITDVdO4GtlyH+qdzNnDEwH7tF7bt84BfVNVDwB/TXBU/alsCv0iy\nKc0beNBbkmyU5rjLjjS74qD5xPrUJJvTHLT/Yds+W+vHlJJsDdxbVafQ7BJ6UfvQbe3ffH+Aag7Q\n3pFk7FP4jE8AGLKGG2l2jcLD6+lkJluGazO/64AFSfZo+2ya5HlTTGY6dwE3JHlLO70kGXvP3MjD\nr21fmq1emP69NA+4tQ2EVzLkXU1n2wa9pUCzH/jdSa6lWWkm2hQd9D7glCQfaZ876WZwVd2f5Dya\nTxMPzrTAqro0yTeBy4Fbae4pNWhL4Kwkm9F86h67u+6EtbafDk+j2Td7A3DZNNM5lWY3znto9pP+\n20xfyyQ+DnwOuKL9VHUD8Abgi8AZSd7e1j8XWwfT+SjwY2B1+3vwDf4z4Cc0x33eXVX3tTn3E+AM\nml0Vp1TVcpi99WMI/5nmRIGHgAeA/07zj/Uq4N955Pr0TuCEJAX8Y881bE6zq/LjNLsNp/KoZZip\nv6XxUfNrl/f+wOeTzKP53/c54OoZv6omOL+U5Ciaf/yn0rxPj6d5L13OI9fdK4AH2/YTgV+Pm97X\ngL9vd+stB/7fOtQ2Y97mYi2kOdvkt1VVSQ6gOZA74RkC7T+4S4G3tPuZ59Ta1Kp1k+REmgOI3xrX\nfgjNbprDJ3jOSNeP9cVUy1D92NC3FNbWrsAX2l0ddwB/MlGnNBd7fYfmAPGo3vBD1aq59xhZP6QJ\nuaUgSeps6AeaJUkDDAVJUsdQkCR1DAVJUsdQkCR1/j+j22cq7fMfUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image.load_img(\"s.jpg\", grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x = x.flatten()\n",
    "x = x.reshape([-1, 48, 48, 1])\n",
    "\n",
    "emotion_prediction = model.predict(x)\n",
    "detect_emotion(emotion_prediction[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYY6SoYaSHHq"
   },
   "outputs": [],
   "source": [
    "#Detecing expessions by feeding a video or webcam\n",
    "import cv2\n",
    "from collections import deque\n",
    "import operator\n",
    "emotion_queue = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx2nAA7ySJjK"
   },
   "outputs": [],
   "source": [
    "# calculate the avearge emotion\n",
    "def smooth_emotions(prediction):\n",
    "    \n",
    "    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "    emotion_values = {'Angry': 0.0, 'Disgust': 0.0, 'Fear': 0.0, 'Happy': 0.0, 'Sad': 0.0, 'Surprise': 0.0, 'Neutral': 0.0}\n",
    "\n",
    "    emotion_probability, emotion_index = max((val, idx) for (idx, val) in enumerate(prediction[0]))\n",
    "    emotion = emotions[emotion_index]\n",
    "\n",
    "        # Append the new emotion and if the max length is reached pop the oldest value out\n",
    "    emotion_queue.appendleft((emotion_probability, emotion))\n",
    "\n",
    "    # Iterate through each emotion in the queue and create an average of the emotions\n",
    "    for pair in emotion_queue:\n",
    "        emotion_values[pair[1]] += pair[0]\n",
    "\n",
    "        # Select the current emotion based on the one that has the highest value\n",
    "    average_emotion = max(emotion_values.items(), key=operator.itemgetter(1))[0]\n",
    "    return average_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzpvxF96SPHy"
   },
   "outputs": [],
   "source": [
    "# preprocessing the input image\n",
    "def process_image(roi_gray, img):\n",
    "        image_scaled = np.array(cv2.resize(roi_gray, (48, 48)), dtype=float)\n",
    "        image_processed = image_scaled.flatten()\n",
    "        image_processed = image_processed.reshape([-1, 48, 48, 1])\n",
    "\n",
    "        prediction = model.predict(image_processed)\n",
    "        emotion = smooth_emotions(prediction)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, \"Emotion: \" + emotion, (50, 450), font, 1, (0, 255, 255), 2)\n",
    "        cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# detecting human faces using HAAR cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0) # 0 for webcam\n",
    "# cap = cv2.VideoCapture(\"video.mp4\") # input the name of your video file here\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = img[y:y + h, x:x + w]\n",
    "        process_image(roi_gray, img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wthQNpF-7a1U"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We used VGG19 model and got a training accuracy of 99.3 % and a testing accuracy of 57.0 %.\n",
    "VGG19 has been a really effective model and also has won the Imagenet competition but with our data we can observe that it clearly tends to overfit as there is humongous difference between training and testing accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btuKsdP6Ck1b"
   },
   "source": [
    "## Contribution\n",
    "\n",
    "In the above analysis:\n",
    "\n",
    "- 60% of the work is done by us which includes\n",
    "  * VGG19 and ResNet implementation\n",
    "  * CNN accuracy improvement\n",
    "  * Live webcam code optimization\n",
    "\n",
    "- 40% of the work is taken from web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg8G0b6cDH5b"
   },
   "source": [
    "## Citations\n",
    "\n",
    "* For face detection - https://www.youtube.com/watch?v=PmZ29Vta7Vc\n",
    "\n",
    "* For VGG19 and ResNet - https://github.com/tflearn/tflearn/tree/master/examples/images\n",
    "\n",
    "* For tflearn - http://tflearn.org/tutorials/\n",
    "\n",
    "* Article on Facial Emotion Recognition using CNN - http://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
    "\n",
    "* VGG19 CNN - https://www.mathworks.com/help/deeplearning/ref/vgg19.html;jsessionid=ccf9599bd865b423281a56299a68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzShatdODYU7"
   },
   "source": [
    "## License\n",
    "\n",
    "<font size=\"4\">MIT License</font>\n",
    "    \n",
    "<b>Copyright (c) 2019 Ritu Agrawal, Nikhil Kashid</b>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG19.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
